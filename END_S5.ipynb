{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END-S5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')\n",
        "import math"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62afac6-7e00-49c5-8d2c-480fd3796581"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1 + np.exp(-x))            # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return  y*(1-y)  # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y*y # write your code here\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKP_HJ2lH6H-",
        "outputId": "a2c23580-4424-43ab-ffde-c8f2695982f1"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3i43gdJIBi1",
        "outputId": "9cad49a1-2c1f-4686-f6cf-f0441ae2ecd0"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11g6dT5QIFlc",
        "outputId": "fe061df7-7388-4ab8-8269-05f6ec6e8e8e"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAvsT7WXIMAv",
        "outputId": "99d6efca-eea6-4948-92f3-e1a6ffc62442"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)   # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)   # write your code here\n",
        "\n",
        "    C = f*C_prev + i*C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v) # write your code here\n",
        "    h = o * tanh(C) # write your code here\n",
        "\n",
        "    v =  np.dot(p.W_v.v, h) +  p.b_v.v   # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v) + 1e-8) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2kPkhOv1LCP",
        "outputId": "36f897c4-3e3e-48de-dd1a-659890f2b32d"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        #idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        idx = np.random.choice(range(X_size))\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "1281fb08-7d55-4353-8435-88489dada55f"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " J?rM'PvpN.“EOz)poKz73A08l)n1;ADGWI\"qI“3E5.oG:,V––0(SG1u3HLVT49R“N’8jR4gqn?6pcPfgK2S8RLOto9bKK,M“eU9g\"AWu“Vr.e“a80CST“1O :gcjJcig9:eLLs pbI?D7rJ;PFN1?KOhkx)vwi–“(.zkNeql?jhxOvlm:;)“fnSnG\n",
            "eC6?)nA61;h,o? \n",
            "----\n",
            "iter 49900, loss 6.296434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QES9orxgFV6E"
      },
      "source": [
        "6.296434"
      ]
    }
  ]
}